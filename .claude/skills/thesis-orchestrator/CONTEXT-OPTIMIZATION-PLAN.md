# Context Optimization Plan for Mode E

**ì‘ì„±ì¼**: 2026-01-28
**ìƒíƒœ**: âœ… Design Complete â†’ Ready for Implementation

---

## ë¬¸ì œ ë¶„ì„

### í˜„ì¬ ìƒí™©
```yaml
ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ëŸ‰: 82,750 / 200,000 tokens (41%)
ì‹¤íŒ¨ ì›ì¸: "Prompt is too long" - Task toolì´ agent ì •ì˜ ì „ì²´ë¥¼ ë¡œë“œ

Agent íŒŒì¼ í¬ê¸°:
  - paper-research-orchestrator.md: 1,045 lines
  - paper-analyzer.md: 856 lines
  - gap-identifier.md: ~600 lines (ì˜ˆìƒ)
  - hypothesis-generator.md: ~600 lines (ì˜ˆìƒ)
  - design-proposer.md: ~700 lines (ì˜ˆìƒ)
  - feasibility-assessor.md: ~500 lines (ì˜ˆìƒ)
  - proposal-integrator.md: ~500 lines (ì˜ˆìƒ)

ì´ Agent ì •ì˜ í¬ê¸°: ~4,800 lines â†’ ~100,000+ tokens (ì¶”ì •)
```

### ê·¼ë³¸ ì›ì¸
1. **Verbose Agent Definitions**: ìƒì„¸í•œ í”„ë ˆì„ì›Œí¬, ì˜ˆì‹œ, ì‘ì„± ê°€ì´ë“œê°€ agent ì •ì˜ì— í¬í•¨
2. **Orchestrator Overhead**: Master orchestratorê°€ 6ê°œ subagent ì •ì˜ë¥¼ ëª¨ë‘ ì°¸ì¡°
3. **No Context Management**: ê° Stage ì™„ë£Œ í›„ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì—†ìŒ

---

## í•´ê²° ë°©ì•ˆ (3ë‹¨ê³„)

### Phase 1: ì¦‰ì‹œ ì‹¤í–‰ (ì˜¤ëŠ˜)

**Orchestrator ìš°íšŒ - ì§ì ‘ ì‹¤í–‰ ë°©ì‹**

```yaml
approach: "ê° Stageë¥¼ ê°œë³„ Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰"

workflow:
  stage_1_paper_analysis:
    executor: "Bash + Python"
    script: ".claude/skills/thesis-orchestrator/scripts/run_paper_analyzer.py"
    input: "{output_dir}/00-paper-based-design/uploaded-paper.pdf"
    output: "{output_dir}/00-paper-based-design/paper-deep-analysis.md"
    context_load: "minimal (only paper content)"

  stage_2_gap_identification:
    executor: "Bash + Python"
    script: ".claude/skills/thesis-orchestrator/scripts/run_gap_identifier.py"
    input: "{output_dir}/00-paper-based-design/paper-deep-analysis.md"
    output: "{output_dir}/00-paper-based-design/strategic-gap-analysis.md"
    context_load: "minimal (only previous output)"

  # ... repeat for stages 3-6

benefits:
  - "No orchestrator overhead"
  - "Each stage runs independently"
  - "Context resets between stages"
  - "Easier debugging and recovery"

implementation_time: "2-3 hours"
```

**ìƒˆë¡œìš´ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼**:
```python
# .claude/skills/thesis-orchestrator/scripts/run_paper_analyzer.py
"""
Standalone script to run Stage 1 (Paper Analysis) without orchestrator.
"""

import sys
from pathlib import Path
from anthropic import Anthropic

def analyze_paper(paper_path: str, output_path: str):
    """Run paper analysis using Claude API directly."""

    # Read paper
    with open(paper_path, 'rb') as f:
        paper_content = f.read()

    # Load minimal prompt (not full agent definition)
    prompt = """
    Analyze this research paper using the following framework:

    1. Research Context (RQ, Theory, Paradigm, Literature)
    2. Methodology Evaluation (Design, Sample, Data Collection, Analysis)
    3. Findings Synthesis (Main findings, Effect sizes, Significance)
    4. Critical Evaluation (Strengths, Weaknesses, Limitations)

    Output: 5-7 pages, GRA compliant (cite page numbers), pTCS 70+
    """

    # Call Claude API
    client = Anthropic()
    response = client.messages.create(
        model="claude-opus-4-5-20251101",
        max_tokens=16000,
        messages=[{
            "role": "user",
            "content": prompt + "\n\nPaper content:\n" + paper_content.decode('utf-8')
        }]
    )

    # Save output
    with open(output_path, 'w') as f:
        f.write(response.content[0].text)

    print(f"âœ… Paper analysis complete: {output_path}")

if __name__ == "__main__":
    analyze_paper(sys.argv[1], sys.argv[2])
```

---

### Phase 2: ë‹¨ê¸° ìµœì í™” (1-2ì¼)

**Agent ì •ì˜ íŒŒì¼ ì¶•ì•½**

```yaml
strategy: "í•µì‹¬ ë¡œì§ë§Œ agent ì •ì˜ì— ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” referencesë¡œ ë¶„ë¦¬"

current_structure:
  paper-analyzer.md:
    - name, description, tools, model (10 lines)
    - Core Principles (20 lines)
    - Analysis Framework (400 lines) â† TOO VERBOSE
    - Quality Standards (100 lines)
    - Execution Guide (150 lines) â† TOO VERBOSE
    - Examples (150 lines) â† TOO VERBOSE

optimized_structure:
  paper-analyzer.md:
    - name, description, tools, model (10 lines)
    - Core Task (50 lines) â† ESSENTIAL ONLY
    - Output Format (30 lines)
    - Quality Gates (20 lines)
    - Total: ~110 lines (87% reduction)

  references/paper-analyzer-framework.md:
    - Detailed analysis framework (moved here)
    - Examples and templates (moved here)
    - Execution guides (moved here)

benefits:
  - "Agent definition: 850 lines â†’ 110 lines (87% reduction)"
  - "Context load: ~100k tokens â†’ ~15k tokens (85% reduction)"
  - "Still accessible via references when needed"

implementation:
  - Refactor all 7 agent files (orchestrator + 6 subagents)
  - Create references/ directory for detailed guides
  - Update agent calls to reference external guides if needed

implementation_time: "4-6 hours"
```

**ìµœì í™” í›„ Agent ì •ì˜ ì˜ˆì‹œ**:
```markdown
---
name: paper-analyzer
description: Deep analysis of research papers (Stage 1)
tools: Read(*), Write(*), WebSearch(*)
model: opus
---

# Paper Analyzer

Analyze research papers using a 4-section framework.

## Core Task

1. **Research Context** (1-2 pages)
   - Research question and theoretical framework
   - Paradigm and literature positioning

2. **Methodology Evaluation** (1-2 pages)
   - Design, sample, data collection, analysis techniques
   - Validity assessment (internal, external, construct)

3. **Findings Synthesis** (1-2 pages)
   - Main findings, effect sizes, statistical/practical significance

4. **Critical Evaluation** (1-2 pages)
   - Theoretical contribution
   - Strengths and weaknesses (acknowledged and unacknowledged)

## Output Format

```markdown
# Deep Analysis: [Paper Title]

## 1. Research Context
[Analysis with page citations]

## 2. Methodology Evaluation
[Analysis with page citations]

## 3. Findings Synthesis
[Analysis with specific statistics]

## 4. Critical Evaluation
[Critical assessment]

## References
[All citations]
```

## Quality Gates

- **GRA Compliance**: All claims cite page numbers (Author, Year, p.X)
- **pTCS Target**: Claim-level 70+, Agent-level 75+
- **Length**: 5-7 pages (3,000-5,000 words)
- **Critical Stance**: Identify unacknowledged limitations

## References

For detailed framework and examples, see:
- `references/paper-analyzer-framework.md` (full analysis framework)
- `references/paper-analyzer-examples.md` (before/after examples)
```

**ì¶•ì•½ íš¨ê³¼**:
- ì›ë³¸: 856 lines â†’ ìµœì í™”: ~110 lines
- ì»¨í…ìŠ¤íŠ¸ ì ˆê°: ~85%

---

### Phase 3: ì¤‘ì¥ê¸° ìµœì í™” (1ì£¼)

**Orchestrator ì¬ì„¤ê³„ - Lightweight Coordinator**

```yaml
current_orchestrator:
  role: "Master coordinator with full subagent definitions"
  size: 1,045 lines
  approach: "Task toolë¡œ subagent í˜¸ì¶œ"
  context_load: "ëª¨ë“  subagent ì •ì˜ ë¡œë“œ"

optimized_orchestrator:
  role: "Lightweight coordinator with minimal logic"
  size: ~150 lines
  approach: "Bash scripts + API calls (orchestrator ìš°íšŒ)"
  context_load: "None (ì§ì ‘ ì‹¤í–‰)"

new_architecture:
  orchestrator.sh:
    description: "Bash script that runs stages sequentially"

    pseudocode: |
      #!/bin/bash

      # Stage 1
      python3 run_paper_analyzer.py $PAPER_PATH $OUTPUT_DIR

      # Stage 2
      python3 run_gap_identifier.py $OUTPUT_DIR/paper-deep-analysis.md $OUTPUT_DIR

      # Stage 3
      python3 run_hypothesis_generator.py $OUTPUT_DIR/strategic-gap-analysis.md $OUTPUT_DIR

      # ... stages 4-6

      # HITL Checkpoint
      echo "ğŸ“‹ HITL-1: Review integrated proposal at $OUTPUT_DIR/integrated-research-proposal.md"

  benefits:
    - "No context overhead (Bash doesn't use Claude context)"
    - "Simple, debuggable, fast"
    - "Easy to pause/resume at any stage"
    - "No 'Prompt too long' errors"

implementation:
  - Write orchestrator.sh
  - Create run_*.py for each stage
  - Update /thesis:start paper-upload to call orchestrator.sh
  - Deprecate paper-research-orchestrator.md agent

implementation_time: "1-2 days"
```

---

## ë©”ëª¨ë¦¬ ìµœì í™” ì „ëµ í†µí•©

ê¸°ì¡´ `MEMORY-OPTIMIZATION-STRATEGY.md`ì™€ í†µí•©:

```yaml
existing_strategies:
  - RLM (Recursive Language Model) for large inputs
  - Context snapshots for recovery
  - Incremental processing

new_strategies:
  - Agent definition minification
  - Orchestrator bypass (direct execution)
  - Reference-based documentation

combined_approach:
  phase0_mode_e:
    method: "Direct execution (Bash + Python)"
    reason: "6 stages Ã— large agents = context explosion"

  phase1_literature:
    method: "RLM agents for synthesis tasks"
    reason: "Wave 4 synthesis needs all 12 previous outputs"

  phase3_writing:
    method: "RLM + Context snapshots"
    reason: "Chapter writing needs all previous context"
```

---

## êµ¬í˜„ ê³„íš

### Week 1: ì¦‰ì‹œ ì‹¤í–‰ (Priority 1)

**Day 1 (ì˜¤ëŠ˜)**:
- [ ] orchestrator.sh ì‘ì„±
- [ ] run_paper_analyzer.py ì‘ì„±
- [ ] Stage 1 í…ŒìŠ¤íŠ¸ ì‹¤í–‰

**Day 2**:
- [ ] run_gap_identifier.py ì‘ì„±
- [ ] run_hypothesis_generator.py ì‘ì„±
- [ ] Stages 2-3 í…ŒìŠ¤íŠ¸ ì‹¤í–‰

**Day 3**:
- [ ] run_design_proposer.py ì‘ì„±
- [ ] run_feasibility_assessor.py ì‘ì„±
- [ ] run_proposal_integrator.py ì‘ì„±
- [ ] Full workflow í…ŒìŠ¤íŠ¸ (Stage 1-6)

### Week 2: ë‹¨ê¸° ìµœì í™” (Priority 2)

**Day 4-5**:
- [ ] Agent ì •ì˜ íŒŒì¼ 7ê°œ ë¦¬íŒ©í† ë§
- [ ] references/ ë””ë ‰í† ë¦¬ ìƒì„± ë° ìƒì„¸ ê°€ì´ë“œ ì´ë™
- [ ] ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ëŸ‰ ì¸¡ì • ë° ë¹„êµ

**Day 6-7**:
- [ ] ìµœì í™”ëœ agent ì •ì˜ë¡œ ì „ì²´ í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (SKILL.md, README.md)

### Week 3: ì¤‘ì¥ê¸° ìµœì í™” (Priority 3)

**Day 8-10**:
- [ ] Orchestrator ì™„ì „ ì œê±° ë° orchestrator.shë¡œ ëŒ€ì²´
- [ ] /thesis:start paper-upload ì»¤ë§¨ë“œ ì—…ë°ì´íŠ¸
- [ ] End-to-end í…ŒìŠ¤íŠ¸ (Mode E ì „ì²´)

**Day 11-12**:
- [ ] ë‹¤ë¥¸ Phase (Phase 1-4) ìµœì í™” ì ìš©
- [ ] RLM í†µí•© í™•ì¸
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

---

## ì˜ˆìƒ íš¨ê³¼

```yaml
before_optimization:
  context_usage:
    orchestrator: "~20k tokens"
    6_subagents: "~80k tokens"
    total: "~100k tokens (50% of limit)"

  result: "Prompt too long" errors

after_phase1:
  context_usage:
    bash_orchestrator: "0 tokens (no Claude context)"
    python_scripts: "minimal (~5k per stage)"
    total: "~5k tokens per stage (2.5%)"

  result: "âœ… No errors, fast execution"

after_phase2:
  context_usage:
    minified_agents: "~15k tokens (if using Task tool)"
    total: "~15k tokens (7.5%)"

  result: "âœ… 85% reduction, Task tool usable again"

after_phase3:
  context_usage:
    orchestrator_sh: "0 tokens"
    direct_api_calls: "~3k per stage"
    total: "~3k tokens per stage (1.5%)"

  result: "âœ… Optimal, production-ready"
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ì¦‰ì‹œ ì‹¤í–‰**: orchestrator.sh + run_*.py ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (ì˜¤ëŠ˜)
2. **í…ŒìŠ¤íŠ¸**: í˜„ì¬ ë…¼ë¬¸ìœ¼ë¡œ Stage 1-6 ì‹¤í–‰ ê²€ì¦ (ë‚´ì¼)
3. **ë‹¨ê¸° ìµœì í™”**: Agent ì •ì˜ ë¦¬íŒ©í† ë§ ì‹œì‘ (ì´ë²ˆ ì£¼)

---

**ì‘ì„±ì**: Claude Code
**ê²€í†  í•„ìš”**: @thesis-orchestrator ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical (ì‹œìŠ¤í…œ ë™ì‘ ë¶ˆê°€ ìƒíƒœ)
